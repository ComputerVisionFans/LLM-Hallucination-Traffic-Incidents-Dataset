{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = open(\"../key.txt\",\"r\").read().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8eODw6MUVrFNWHowlXDSMTMkAlave\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1704636928,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"To use the ChatGPT API:\\n\\n1. First, you will need an OpenAI API key, which you'll get by creating an account on the OpenAI website. \\n\\n2. Make sure you have the OpenAI GPT-3 Python client installed in your environment. You can install it using pip:\\n\\n   ```\\n    pip install openai\\n   ```\\n\\n3. You can use the OpenAI API for making requests with Python:\\n\\n   ```python\\n    import openai\\n\\n    openai.api_key = 'your-api-key'\\n\\n    response = openai.ChatCompletion.create(\\n      model=\\\"gpt-3.5-turbo\\\",\\n      messages=[\\n            {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant.\\\"},\\n            {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Who won the world series in 2020?\\\"},\\n        ]\\n    )\\n\\n    print(response['choices'][0]['message']['content'])\\n    ```\\n\\n4. Replace 'your-api-key' with your actual OpenAI API key.\\n\\n5. This is a simple example of using the Chat API for continous two way conversation. \\n\\n6. The `messages` parameter takes an array of message objects. Each message object has a 'role' which can be 'system', 'user', or 'assistant', and 'content' which is the content of the message from the role.\\n\\n7. Remember that the 'system' message is used to set the behavior of the assistant and the 'user' message is what your assistant will respond to.\\n\\n8. The assistant\\u2019s reply can be extracted from `response['choices'][0]['message']['content']`.\\n\\n9. Please note that there are certain charges/usage costs associated with using the API, which depend on the number of tokens processed. You can find detailed information about cost and tokens in the OpenAI Pricing page and OpenAI documentation.\\n\\nThis is a simplified example, you might need to handle more complex scenarios like multi-turn conversation, error handling etc. For better understanding, refer to documentation provided by OpenAI.\"\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 15,\n",
      "    \"completion_tokens\": 414,\n",
      "    \"total_tokens\": 429\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages = [{\"role\": \"user\", \"content\": \"How can i use Chatgpt-api\"}]\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the ChatGPT API:\n",
      "\n",
      "1. First, you will need an OpenAI API key, which you'll get by creating an account on the OpenAI website. \n",
      "\n",
      "2. Make sure you have the OpenAI GPT-3 Python client installed in your environment. You can install it using pip:\n",
      "\n",
      "   ```\n",
      "    pip install openai\n",
      "   ```\n",
      "\n",
      "3. You can use the OpenAI API for making requests with Python:\n",
      "\n",
      "   ```python\n",
      "    import openai\n",
      "\n",
      "    openai.api_key = 'your-api-key'\n",
      "\n",
      "    response = openai.ChatCompletion.create(\n",
      "      model=\"gpt-3.5-turbo\",\n",
      "      messages=[\n",
      "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
      "            {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    print(response['choices'][0]['message']['content'])\n",
      "    ```\n",
      "\n",
      "4. Replace 'your-api-key' with your actual OpenAI API key.\n",
      "\n",
      "5. This is a simple example of using the Chat API for continous two way conversation. \n",
      "\n",
      "6. The `messages` parameter takes an array of message objects. Each message object has a 'role' which can be 'system', 'user', or 'assistant', and 'content' which is the content of the message from the role.\n",
      "\n",
      "7. Remember that the 'system' message is used to set the behavior of the assistant and the 'user' message is what your assistant will respond to.\n",
      "\n",
      "8. The assistant’s reply can be extracted from `response['choices'][0]['message']['content']`.\n",
      "\n",
      "9. Please note that there are certain charges/usage costs associated with using the API, which depend on the number of tokens processed. You can find detailed information about cost and tokens in the OpenAI Pricing page and OpenAI documentation.\n",
      "\n",
      "This is a simplified example, you might need to handle more complex scenarios like multi-turn conversation, error handling etc. For better understanding, refer to documentation provided by OpenAI.\n"
     ]
    }
   ],
   "source": [
    "reply = completion['choices'][0].message.content\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pydantic in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (2.5.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pydantic) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pydantic) (4.9.0)\n",
      "Requirement already satisfied: pyecharts in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (2.0.4)\n",
      "Requirement already satisfied: jinja2 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pyecharts) (3.1.2)\n",
      "Requirement already satisfied: prettytable in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pyecharts) (3.9.0)\n",
      "Requirement already satisfied: simplejson in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pyecharts) (3.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from jinja2->pyecharts) (2.1.1)\n",
      "Requirement already satisfied: wcwidth in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from prettytable->pyecharts) (0.2.5)\n",
      "Requirement already satisfied: fastapi in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (0.104.1)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from fastapi) (3.7.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from fastapi) (2.5.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from fastapi) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.0.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/biodtmin/.conda/envs/private/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.14.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install matplotlib\n",
    "!pip install pydantic\n",
    "!pip install pyecharts\n",
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT GPT generated top station data\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from pyecharts.charts import Bar, Page, Pie, Grid\n",
    "from pyecharts import options as opts\n",
    "\n",
    "\n",
    "\n",
    "# Define the function to plot the gpt data\n",
    "def plot_gpt_data_to_html(filtered_gpt_data):\n",
    "    data = filtered_gpt_data\n",
    "\n",
    "    # Updated pattern to handle both data formats\n",
    "    pattern = r'(\\w[\\w\\s,]*[^\\s])\\s\\((\\d+)\\)|\\(([\\w\\s,]+), (\\d+)\\)'\n",
    "    matches = re.findall(pattern, data)\n",
    "\n",
    "    # Extracting station names and frequencies considering both matching groups from the updated pattern\n",
    "    stations = [match[0] if match[2] == '' else match[2] for match in matches]\n",
    "    frequencies = [int(match[1]) if match[3] == '' else int(match[3]) for match in matches]\n",
    "\n",
    "    bar_chart = (\n",
    "        Bar()\n",
    "        .add_xaxis(stations)\n",
    "        .add_yaxis(\"Frequenz\", frequencies, tooltip_opts=opts.TooltipOpts(is_show=True, trigger=\"axis\", axis_pointer_type=\"cross\"))\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"Betroffene Dauer\"),  \n",
    "            xaxis_opts=opts.AxisOpts(\n",
    "                name=\"Stationen\",  # X-Axis title\n",
    "                axislabel_opts=opts.LabelOpts(\n",
    "                    rotate=45,   # Try 45-degree rotation\n",
    "                    font_size=8  # Further reduce font size\n",
    "                )\n",
    "            ),\n",
    "            yaxis_opts=opts.AxisOpts(\n",
    "                name=\"Frequenz\",  # Y-Axis title\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return bar_chart.render_notebook()\n",
    "\n",
    "\n",
    "\n",
    "# Define the function to plot the line data\n",
    "def plot_line_data_to_html(lines_data_list):\n",
    "    data = lines_data_list\n",
    "    page = Page(layout=Page.SimplePageLayout)\n",
    "    bars = []\n",
    "\n",
    "    for idx, week_data in enumerate(data, 1):\n",
    "        labels, values = zip(*week_data)\n",
    "        bar_chart = (\n",
    "            Bar()\n",
    "            .add_xaxis(list(labels))\n",
    "            .add_yaxis(f\"Woche {idx}\", list(values), label_opts=opts.LabelOpts(is_show=False))\n",
    "            .set_global_opts(\n",
    "                title_opts=opts.TitleOpts(title=f\"Woche {idx} Vorfälle je Linie\"),\n",
    "                xaxis_opts=opts.AxisOpts(\n",
    "                    name=\"Linie\",  # X-Axis title\n",
    "                    axislabel_opts=opts.LabelOpts(rotate=45)  # Optional: Rotate x-axis labels if needed\n",
    "                ),\n",
    "                yaxis_opts=opts.AxisOpts(\n",
    "                    name=\"Anzahl Vorfälle\"  # Y-Axis title\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        bars.append(bar_chart)\n",
    "\n",
    "    page.add(*bars)\n",
    "    \n",
    "    print(\"Generating plot...\")\n",
    "    # Return the embeddable HTML\n",
    "    #return page.render_embed()\n",
    "    return page.render_notebook()\n",
    "\n",
    "# Define the function to plot the accident data\n",
    "def plot_accident_data_to_html(accident_data_list):\n",
    "    data = accident_data_list\n",
    "\n",
    "    def generate_pie(data_item, title):\n",
    "        categories = list(data_item.keys())\n",
    "        values = list(data_item.values())\n",
    "        pie = (\n",
    "            Pie()\n",
    "            .add(\"\", [list(z) for z in zip(categories, values)])\n",
    "            .set_global_opts(title_opts=opts.TitleOpts(title=title), legend_opts=opts.LegendOpts(orient=\"vertical\", pos_top=\"15%\", pos_left=\"85%\"))\n",
    "            .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {d}%\"))  # Displaying category name and percentage\n",
    "        )\n",
    "        return pie\n",
    "\n",
    "    page = Page()\n",
    "    for index, data_item in enumerate(data):\n",
    "        page.add(generate_pie(data_item, f\"Woche {index+1}\"))\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    # Return the embeddable HTML\n",
    "    #return page.render_embed()\n",
    "    return page.render_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import openai\n",
    "import os\n",
    "from pyecharts import *\n",
    "#from plot import plot_line_data_to_html, plot_accident_data_to_html, plot_gpt_data_to_html \n",
    "\n",
    "load_dotenv()\n",
    "# Configure the OpenAI API client\n",
    "#openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "#openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "#openai.api_base = os.getenv(\"OPENAI_API_BASE\")  # Your Azure OpenAI resource's endpoint value.\n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the function to generate the response\n",
    "#def generate_response(resulted_data):\n",
    "#    response = openai.ChatCompletion.create(\n",
    "#        model=\"gpt-4\",\n",
    "        #engine=os.getenv(\"DEPLOYMENT_NAME\"), # The deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 model.\n",
    "#        temperature = 0.4,\n",
    "#        messages=[\n",
    "#            {\"role\": \"system\", \"content\": \"Du bist ein Analyse-Chatbot. Aus den bereitgestellten JSON-Daten antwortest du auf Nutzerfragen, um Statistiken basierend auf Benutzereingaben zu erstellen. Dies sind die Kontext-JSON-Daten:\"+ resulted_data},\n",
    "#            {\"role\": \"user\", \"content\": \"Im JSON-Datenkontext der Wiener-Linie sind unter Titel betroffene Linien und unter 'Beschreibung' betroffene Stationen verzeichnet. Welche 10 Stationen sind am häufigsten betroffen? Geben Sie nur in diesem Format aus: (Stationsname, Gesamtzahl der Vorfälle). Zum Beispiel: (Rotkreuzplatz, 10).\"\n",
    "#            }\n",
    "#        ]\n",
    "#    )\n",
    "#    return response['choices'][0]['message']['content']\n",
    "\n",
    "def generate_response(resulted_data):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-0314\",\n",
    "    # engine=os.getenv(\"DEPLOYMENT_NAME\"), # The deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 model.\n",
    "    temperature=tem,\n",
    "    messages=[\n",
    "      {\"role\": \"user\",\n",
    "       \"content\": \"Du bist ein Analyst. Aus den bereitgestellten Daten antwortest du auf Nutzerfragen, um Statistiken basierend auf Benutzereingaben zu erstellen. Dies sind die Kontext-List-Daten:\" \n",
    "                  + resulted_data \n",
    "                  + \"Im Datenkontext der Wiener-Linie sind unter (title) betroffene Linien unter (start) betroffene Startzeit und unter (end) betroffene Endzeit verzeichnet. Welche 10 Linien sind am häufigsten betroffen? Wie lange ist die insgesamt betroffene Zeit, die jede dieser 10 verzögerten Linien？Geben Sie nur in diesem Format aus: 1. (Linien, Gesamtzahl der Vorfälle, insgesamt betroffene Zeit in Format Stunden Minuten Sekunden). Zum Beispiel: 1. (39A, 2, 5Stunden 24Minuten 32Sekunden).\"\n",
    "       \n",
    "      #\"role\": \"user\",\n",
    "      # \"content\": \"Bitte geben Sie die Ergebnisse in absteigender Reihenfolge der insgesamt Verspätungszeit der Linien aus.\"\n",
    "      }\n",
    "    ]\n",
    "  )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "# Define the function to filter the accident data\n",
    "def get_incident_data(data, start_time, end_time):        \n",
    "    # Convert the provided timestamp range strings to datetime objects\n",
    "    ##############################################\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_datetime = datetime.strptime(start_time, date_format)\n",
    "    end_datetime = datetime.strptime(end_time, date_format)\n",
    "    \n",
    "    #gpt filter\n",
    "    filtered_incidents = [\n",
    "        {\n",
    "            'title': entry['title'],\n",
    "            'description': entry['description'],\n",
    "            'start': entry['start'],\n",
    "            'end': entry['end']\n",
    "            \n",
    "        } \n",
    "        for entry in data['incidents'] \n",
    "        if start_datetime <= datetime.strptime(entry['start'], date_format) <= end_datetime\n",
    "    ]\n",
    "        \n",
    "    resulted_data = json.dumps(filtered_incidents)\n",
    "    #resulted_data = data\n",
    "    #############################################\n",
    "    print(resulted_data)\n",
    "    \n",
    "    #filtered_gpt_data = ''\n",
    "    filtered_gpt_data = generate_response(resulted_data)\n",
    "    \n",
    "    return filtered_gpt_data\n",
    "\n",
    "\n",
    "\n",
    "# Define the function to filter the line data \n",
    "def get_top10_lines(data, start_time, end_time):        \n",
    "    # Convert the provided timestamp range strings to datetime objects\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_datetime = datetime.strptime(start_time, date_format)\n",
    "    end_datetime = datetime.strptime(end_time, date_format)\n",
    "    \n",
    "    filtered_lines_incidents = []\n",
    "    for entry in data['incidents']:\n",
    "        if start_datetime <= datetime.strptime(entry['start'], date_format) <= end_datetime:\n",
    "            filtered_lines_incidents.append(entry['lines'])\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "\n",
    "    # Flatten the list of lists\n",
    "    flattened_list = [item for sublist in filtered_lines_incidents for item in sublist]\n",
    "    # Calculate the frequency of each element\n",
    "    element_frequencies = Counter(flattened_list)\n",
    "    # Get the top 10 most common elements and their frequencies\n",
    "    top_10 = element_frequencies.most_common(10)\n",
    "\n",
    "    return top_10\n",
    "\n",
    "# Define the function to filter the accident time data\n",
    "def get_accident_time_sum(data, start_time, end_time):\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_datetime = datetime.strptime(start_time, date_format)\n",
    "    end_datetime = datetime.strptime(end_time, date_format)\n",
    "\n",
    "    filtered_accident_sum = {\"Verkehrsunfall\": 0, \"Falschparker\": 0}\n",
    "    #for entry in data['incidents']:\n",
    "    for entry in data['incidents']:\n",
    "        # Data validation for the 'start' and 'end' timestamps\n",
    "        if 'start' not in entry or 'end' not in entry:\n",
    "            #print(\"Missing 'start' or 'end' in entry:\", entry)\n",
    "            continue\n",
    "        if not entry['start'] or not entry['end']:\n",
    "            #print(\"Empty 'start' or 'end' timestamp in entry:\", entry)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            start_incident_datetime = datetime.strptime(entry['start'], date_format)\n",
    "            end_incident_datetime = datetime.strptime(entry['end'], date_format)\n",
    "        except ValueError as e:\n",
    "            #print(f\"Error parsing timestamp in entry {entry}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Check the incident title and compute the time sum\n",
    "        if start_datetime <= start_incident_datetime <= end_datetime and (\"Verkehrsunfall\" in entry['title'] or \"Falschparker\" in entry['title']):\n",
    "            if \"Verkehrsunfall\" in entry['title']:\n",
    "                filtered_accident_sum['Verkehrsunfall'] += (end_incident_datetime - start_incident_datetime).total_seconds() / 60\n",
    "            if \"Falschparker\" in entry['title']:\n",
    "                filtered_accident_sum['Falschparker'] += (end_incident_datetime - start_incident_datetime).total_seconds() / 60\n",
    "\n",
    "    filtered_accident_sum = {key: (round(value, 2) if isinstance(value, float) else value) for key, value in filtered_accident_sum.items()}\n",
    "\n",
    "    return filtered_accident_sum\n",
    "\n",
    "\n",
    "# Define the function to generate the date ranges\n",
    "def get_date_ranges():\n",
    "    # Initialize the end date to today's date at 00:00:00\n",
    "    end_time = datetime.strptime('2023-08-16 00:00:00.00000','%Y-%m-%d %H:%M:%S.%f')\n",
    "    # Define the time interval (1 week = 7 days)\n",
    "    interval = timedelta(days=1)\n",
    "    date_ranges = []\n",
    "    # Generate the ranges\n",
    "    for _ in range(3):\n",
    "        start_time = end_time - interval\n",
    "        date_ranges.append((start_time, end_time))\n",
    "        end_time = start_time\n",
    "    return date_ranges\n",
    "\n",
    "\n",
    "# Define the function to generate the Subway_line data\n",
    "def get_line_data(date_ranges):\n",
    "    with open('../original/Wiener_2013-2023.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    #top 10 line data\n",
    "    lines_data_list = []\n",
    "    for start, end in date_ranges:\n",
    "        start_str = start.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = end.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        filetered_top_10_line_data = get_top10_lines(data, start_str, end_str)\n",
    "        #print(\"Line data from data analysis:\")\n",
    "        lines_data_list.append(filetered_top_10_line_data)\n",
    "    print(lines_data_list)\n",
    "    return plot_line_data_to_html(lines_data_list)\n",
    "\n",
    "\n",
    "# Define the function to generate the accident data\n",
    "def get_accident_data(date_ranges):\n",
    "    with open('../original/Wiener_2013-2023.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    #accident time sum data\n",
    "    accident_data_list = []\n",
    "    for start, end in date_ranges:\n",
    "        start_str = start.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = end.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        filtered_accident_time_data = get_accident_time_sum(data, start_str, end_str)\n",
    "        #print(\"Filtered Accident time data\")\n",
    "        accident_data_list.append(filtered_accident_time_data)\n",
    "    print(accident_data_list)\n",
    "    return plot_accident_data_to_html(accident_data_list)\n",
    "\n",
    "##########################################\n",
    "# Define the function to generate the gpt data\n",
    "def get_gpt_data(date_ranges):\n",
    "    # Use the list of tuples in a for loop\n",
    "    data = read_data()\n",
    "    for start, end in date_ranges:\n",
    "        start_str = start.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = end.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print(f\"Start: {start_str}, End: {end_str}\")\n",
    "        filtered_gpt_data = get_incident_data(data, start_str, end_str)\n",
    "        #filtered_gpt_data = get_incident_data(data)\n",
    "        \n",
    "        print(\"Filtered GPT data:\")\n",
    "        print(filtered_gpt_data)\n",
    "        break\n",
    "    #return plot_gpt_data_to_html(filtered_gpt_data)\n",
    "#############################################\n",
    "# Define the function to read the data\n",
    "def read_data():\n",
    "    with open('../original/Wiener_2013-2023.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data \n",
    "#get_line_data(get_date_ranges())\n",
    "#get_accident_data(get_date_ranges())\n",
    "#get_gpt_data(get_date_ranges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2023-08-15 00:00:00, End: 2023-08-16 00:00:00\n",
      "[{\"title\": \"D: Fremder Verkehrsunfall\", \"description\": \"Wegen eines fremden Verkehrsunfalles im Bereich Zahnradbahnstra\\u00c3\\u009fe f\\u00c3\\u00a4hrt die Linie D nur zwischen Absberggasse und Liechtenwerder Platz. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 00:15 Uhr!\", \"start\": \"2023-08-15 23:37:31\", \"end\": \"2023-08-15 23:59:01\"}, {\"title\": \"42: Falschparker\", \"description\": \"Wegen eines Falschparkers im Bereich Kreuzgasse 21 ist die Linie 42 in Fahrtrichtung Schottentor U an der Weiterfahrt gehindert. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 19:00 Uhr!\", \"start\": \"2023-08-15 18:44:04\", \"end\": \"2023-08-15 19:46:02\"}, {\"title\": \"26: Schadhaftes Fahrzeug\", \"description\": \"Die Stra\\u00c3\\u009fenbahnlinie 26 kann wegen eines schadhaften Fahrzeuges derzeit in beiden Richtungen nur unregelm\\u00c3\\u00a4\\u00c3\\u009fig fahren.\", \"start\": \"2023-08-15 18:38:38\", \"end\": \"2023-08-15 20:39:02\"}, {\"title\": \"U4: Verunreinigung\", \"description\": \"Wegen einer Verunreinigung in der Station L\\u00c3\\u00a4ngenfeldgasse U ist die Linie U4 in Fahrtrichtung H\\u00c3\\u00bctteldorf an der Weiterfahrt gehindert. Das St\\u00c3\\u00b6rungsende ist derzeit nicht absehbar.\", \"start\": \"2023-08-15 18:30:32\", \"end\": \"2023-08-15 20:37:01\"}, {\"title\": \"57A: Polizeieinsatz\", \"description\": \"Die Autobuslinie 57A kann wegen eines Polizeieinsatzes derzeit in beiden Richtungen nur unregelm\\u00c3\\u00a4\\u00c3\\u009fig fahren.\", \"start\": \"2023-08-15 17:03:37\", \"end\": \"2023-08-15 18:30:02\"}, {\"title\": \"U1: Versp\\u00c3\\u00a4tungen\", \"description\": \"Die U-Bahnlinie U1 kann wegen einer Betriebsst\\u00c3\\u00b6rung derzeit in beiden Richtungen nur unregelm\\u00c3\\u00a4\\u00c3\\u009fig fahren.\", \"start\": \"2023-08-15 16:38:05\", \"end\": \"2023-08-15 17:25:01\"}, {\"title\": \"60: Fahrleitungsgebrechen\", \"description\": \"Wegen eines Fahrleitungsgebrechens im Bereich Ge\\u00c3\\u009flgasse 9 f\\u00c3\\u00a4hrt die Linie 60 nur zwischen Westbahnhof S U und Hofwiesengasse. Ersatzweise ben\\u00c3\\u00bctzen Sie bitte die Linie 60A . Das St\\u00c3\\u00b6rungsende ist derzeit nicht absehbar.\", \"start\": \"2023-08-15 16:28:59\", \"end\": \"2023-08-15 20:19:01\"}, {\"title\": \"30A , 36B: Rettungseinsatz\", \"description\": \"Wegen eines Rettungseinsatzes in der Justgasse sind die Linien 30A in Richtung Stammersdorfer Freiheitsplatz sowie 36B in Richtung Bellgasse an der Weiterfahrt gehindert. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 14:45 Uhr.\", \"start\": \"2023-08-15 14:23:51\", \"end\": \"2023-08-15 16:28:01\"}, {\"title\": \"U1: Rettungseinsatz\", \"description\": \"Wegen eines Rettungseinsatzes werden die Z\\u00c3\\u00bcge der Linie U1 zwischen den Stationen Keplerplatz U und S\\u00c3\\u00bcdtiroler Platz - Hauptbahnhof S U \\u00c3\\u00bcber Gleis 2 gef\\u00c3\\u00bchrt. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 14:30 Uhr!\", \"start\": \"2023-08-15 13:59:15\", \"end\": \"2023-08-15 14:55:01\"}, {\"title\": \"2: Verkehrsunfall\", \"description\": \"Wegen eines Verkehrsunfalls im Bereich Wilhelminenstra\\u00c3\\u009fe ist die Linie 2 in Fahrtrichtung Friedrich-Engels-Platz an der Weiterfahrt gehindert. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 14:10 Uhr!\", \"start\": \"2023-08-15 13:55:15\", \"end\": \"2023-08-15 16:27:02\"}, {\"title\": \"66A: Schadhaftes Fahrzeug\", \"description\": \"Die Autobuslinie 66A kann wegen eines schadhaften Fahrzeuges derzeit in beiden Richtungen nur unregelm\\u00c3\\u00a4\\u00c3\\u009fig fahren.\", \"start\": \"2023-08-15 13:35:49\", \"end\": \"2023-08-15 14:45:01\"}, {\"title\": \"68A , 68B: Falschparker\", \"description\": \"Wegen eines Falschparkers im Bereich Waldgasse 32 sind die Linien 68A , 68B in Fahrtrichtung Reumannplatz U an der Weiterfahrt gehindert. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 12:20 Uhr!\", \"start\": \"2023-08-15 11:57:32\", \"end\": \"2023-08-15 13:08:01\"}, {\"title\": \"D, 5 , 33: Polizeieinsatz\", \"description\": \"Wegen eines Polizeieinsatzes im Julius-Tandler-Platz sind die Linien D in Richtung Nu\\u00c3\\u009fdorf, 5 in Richtung Westbahnhof und 33 in Richtung Augasse an der Weiterfahrt gehindert. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 11 Uhr.\", \"start\": \"2023-08-15 10:44:48\", \"end\": \"2023-08-15 11:59:01\"}, {\"title\": \"U6: Rettungseinsatz\", \"description\": \"Wegen eines Rettungseinsatzes werden die Z\\u00c3\\u00bcge der Linie U6 zwischen den Stationen Josefst\\u00c3\\u00a4dter Stra\\u00c3\\u009fe U und Alser Stra\\u00c3\\u009fe U \\u00c3\\u00bcber Gleis 1 gef\\u00c3\\u00bchrt. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 11:00 Uhr!\", \"start\": \"2023-08-15 10:34:57\", \"end\": \"2023-08-15 11:34:02\"}, {\"title\": \"30A: Rettungseinsatz\", \"description\": \"Wegen eines Rettungseinsatzes im Haltestellenbereich Bernreiterplatz ist die Linie 30A in Fahrtrichtung Neu Leopoldau an der Weiterfahrt gehindert. Die St\\u00c3\\u00b6rung dauert voraussichtlich bis 09:30 Uhr!\", \"start\": \"2023-08-15 09:05:38\", \"end\": \"2023-08-15 12:01:01\"}, {\"title\": \"14A: Feuerwehreinsatz\", \"description\": \"Nach einer Fahrtbehinderung kommt es auf der Linie 14A zu unterschiedlichen Intervallen.\", \"start\": \"2023-08-15 07:02:09\", \"end\": \"2023-08-15 08:13:01\"}, {\"title\": \"U6: Versp\\u00c3\\u00a4tungen\", \"description\": \"Die U-Bahnlinie U6 kann wegen eines schadhaften Fahrzeuges derzeit in beiden Richtungen nur unregelm\\u00c3\\u00a4\\u00c3\\u009fig fahren.\", \"start\": \"2023-08-15 04:39:56\", \"end\": \"2023-08-15 05:15:01\"}]\n",
      "Filtered GPT data:\n",
      "1. (D, 2, 1Stunde 21Minuten 30Sekunden)\n",
      "2. (42, 1, 1Stunde 1Minute 58Sekunden)\n",
      "3. (26, 1, 2Stunden 23Sekunden)\n",
      "4. (U4, 1, 2Stunden 6Minuten 29Sekunden)\n",
      "5. (57A, 1, 1Stunde 26Minuten 25Sekunden)\n",
      "6. (U1, 2, 1Stunde 3Minuten 2Sekunden)\n",
      "7. (60, 1, 3Stunden 50Minuten 2Sekunden)\n",
      "8. (30A, 2, 2Stunden 55Minuten 23Sekunden)\n",
      "9. (2, 1, 2Stunden 31Minuten 47Sekunden)\n",
      "10. (66A, 1, 1Stunde 9Minuten 12Sekunden)\n"
     ]
    }
   ],
   "source": [
    "get_gpt_data(get_date_ranges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
